{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "\n",
    "When we have to find sometype of real numbers like price , weight or we can say absolute numbers then we can use the Regression \n",
    "\n",
    "\n",
    "--> We also have Polynomial Regression( we'll learn later)\n",
    "  Logistic regression is used for a classification problem. \n",
    "How classification problem diff from regression \n",
    "--  yes no , good , bad  where we are expecting the output out of cose and predifened number numbers or pre defined clases where prediction is not a number this come in classification. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Criteria \n",
    "1. Confusion matrix \n",
    "2. F1\n",
    "3. specificity \n",
    "4. AUC -Area under curve \n",
    "5. ROC - Reciever Operator Characterstics\n",
    "6. Recall \n",
    "7. Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge ,Lasso , RidgeCV , ElasticNet , ElasticNetCV, LinearRegression , LassoCV\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix , roc_curve, roc_auc_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label - outcome (binary result so binary class classification)\n",
    "\n",
    "\n",
    "\n",
    "features - multi column features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregnancies is neither standard normal distribution nor normal distribution\n",
    "#### gLucose - look like normally distrbuted\n",
    "#### Skin thickness - Normal distributed with some outliers\n",
    "#### Isulin - little bit skewed on right side\n",
    "#### Bmi - Normally Distributed\n",
    "#### Diabetes Prediction -  skewed right\n",
    "#### Age - Right Skewed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From pearson graph we can say that their is no much multi collinearity but we can make sure it by VIF \n",
    "Their is no null value in dataset\n",
    "From Histogram we can see that datset is skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their are many Zeros value in dataset in different column like blood pressure  of a person cannot be zero similarly for glucose and bm for living person this may be due to device failure which is recording this value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will be filling those Zeros value by something like mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def TKPY_remove_zeros(df):\n",
    "#   for column in df.columns:\n",
    "#     print(df[column])\n",
    "#     df[column] = df[column].replace(0,df[column].mean())\n",
    "# TKPY_remove_zeros(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# sns.pairplot(data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['BMI']=df['BMI'].replace(0,df['BMI'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['BloodPressure']=df['BloodPressure'].replace(0,df['BloodPressure'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Insulin']=df['Insulin'].replace(0,df['Insulin'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Glucose']=df['Glucose'].replace(0,df['Glucose'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['SkinThickness']=df['SkinThickness'].replace(0,df['SkinThickness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding Outliers in data via boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "sns.boxplot(data=df , ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from thise we can see insulin column has so many outliers, Bmi and skin Thickness has some outliers etc . \n",
    "we need to handle this outliers by scalling , IQR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def TKPY_outliers_handler(df):\n",
    "#     Q1 = df.quantile(0.25)\n",
    "#     Q3 = df.quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     l=[]\n",
    "#     l=df.columns\n",
    "#     df = df[~((df[l]< (Q1 - 1.5 * IQR)) |(df[l]> (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "        \n",
    "# TKPY_outliers_handler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "sns.boxplot(data=df , ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q= df['Insulin'].quantile(.95)  # to dec outliers we try decreasing dataset by some percentages trying to get low outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new=df[df['Insulin']<q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "sns.boxplot(data=df_new , ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q= df['Pregnancies'].quantile(.98) \n",
    "df_new=df[df['Pregnancies']<q]\n",
    "\n",
    "q= df_new['BMI'].quantile(.99) \n",
    "df_new=df[df['BMI']<q]\n",
    "\n",
    "q= df_new['SkinThickness'].quantile(.99) \n",
    "df_new=df[df['SkinThickness']<q]\n",
    "\n",
    "q= df_new['DiabetesPedigreeFunction'].quantile(.99) \n",
    "df_new=df[df['DiabetesPedigreeFunction']<q]\n",
    "\n",
    "q= df_new['Age'].quantile(.98) \n",
    "df_new=df[df['Age']<q]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "sns.boxplot(data=df_new , ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProfileReport(df_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def outlier_removal(self,data):\n",
    "#     def outlier_limits(col):\n",
    "#         Q3,Q1=np.nanpercentile(col,[75,25])\n",
    "#         IQR=Q3-Q1\n",
    "#         Ul=Q3+1.5*IQR\n",
    "#         LL=Q1-1.5*IQR\n",
    "#         return UL, LL\n",
    "#     for column in df.columns:\n",
    "#         if df[column].dtype != 'int64':\n",
    "#             UL,LL = outlier_limits(df[column])\n",
    "#             df[column]=np.where((df[column]>UL | (df[column]<LL), np.nan , df[column])\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=df_new['Outcome']\n",
    "x=df_new.drop(columns=['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is varying too much like in glucose their is huge difference between min and maximun value similarly for bmi  so  our data is flactuating too much we need to scale it using Standard Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "d=pd.DataFrame(scaler.fit_transform(df_new))\n",
    "x_scales=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProfileReport(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can see in stats that min and max value are near and less flactuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,20))\n",
    "sns.boxplot(data=d , ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif_df=pd.DataFrame([[x.columns[i],variance_inflation_factor(x_scales,i)] for i in range(x_scales.shape[1])],columns=[\"Feature\",\"VIF_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vif score < 10 so no need to remove any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test=train_test_split(x_scales,y,test_size=.10 , random_state=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr=LogisticRegression(verbose=1) # using default  solver lfbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr.predict_proba([x_test[1]]) # for class 0 probab and for class 1 probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TKPY_logr_predict(a,b,c,d,e,f,g,h):\n",
    "    q=[a,b,c,d,e,f,g,h]\n",
    "    test= scaler.fit_transform([q])\n",
    "    output= logr.predict_proba(test) # for class 1 probab and for class 2  probab for the following test case\n",
    "    return output\n",
    "print(TKPY_logr_predict(8,183.0,64.0,20.536458,79.799479,23.3,0.672,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr.predict([x_test[1]]) # classes wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr.predict_log_proba([x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.iloc[1] # checking actual value of y for predicted set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr.predict([x_test[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr1=LogisticRegression(verbose=1, solver='liblinear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr1.predict_proba([x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr1.predict([x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logr1.predict_log_proba([x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#accuracy for both model logr and logr1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred1=logr1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred=logr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=(confusion_matrix(y_test,y_pred1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_eval(y_true,y_pred):\n",
    "    tn,fp,fn,tp=confusion_matrix(y_test,y_pred).ravel()\n",
    "    accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    specificity=tn/(fp+tn)\n",
    "    f1=2*(recall*precision)/(recall+precision)\n",
    "    result={\"Accuracy =\":accuracy,\"Precision=\":precision,\"Recall=\":recall,\"Specificity=\":specificity,\"f1_score\":f1}\n",
    "    return result\n",
    "model_eval(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_eval(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_curve(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc=roc_auc_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " fpr,tpr,threshold =roc_curve(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr,color='red',label='ROC')\n",
    "plt.plot([0,1],[0,1],color='darkblue', linestyle='--',label='ROC Curve( area=%0.2f)' %auc)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title('Receiver Operating Characteristics Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(\n",
    "    svm.SVC(kernel=\"linear\", probability=True, random_state=random_state)\n",
    ")\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "lw=2\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "macro_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "weighted_roc_auc_ovo = roc_auc_score(\n",
    "    y_test, y_prob, multi_class=\"ovo\", average=\"weighted\"\n",
    ")\n",
    "macro_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "weighted_roc_auc_ovr = roc_auc_score(\n",
    "    y_test, y_prob, multi_class=\"ovr\", average=\"weighted\"\n",
    ")\n",
    "print(\n",
    "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    ")\n",
    "print(\n",
    "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.validation import check_array\n",
    "a = np.array([10,20,30,40]).reshape(1,-1)\n",
    "b=check_array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a ['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list1 = [10, 20, 4, 45, 99]\n",
    "# new_list = set(list1)\n",
    "# Removing the largest element from temp list\n",
    "def indices23(new_list):\n",
    "    l=[]\n",
    "    for i in range(0,2):\n",
    "        new_list.remove(max(new_list))\n",
    "        l.append(max(new_list))\n",
    "    return l\n",
    "print(indices23(list(range(25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MultiplyAdd:\n",
    "    def __init__(self,m=4,c=3):\n",
    "        self.m=m\n",
    "        self.c=c\n",
    "  \n",
    "    def run(self,x):\n",
    "        self.x=x\n",
    "        return(self.m*self.x + self.c)\n",
    "  \n",
    "  \n",
    "mult_add=MultiplyAdd(m=3,c=4)\n",
    "mult_add.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
